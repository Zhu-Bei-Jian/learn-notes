# Entity无感热更新

负载均衡策略：
    user请求entityService时，如果该user是首次负载均衡，则从所有可用entity中选取负载压力最小的，并在redis中记录svrID和userID的对应关系；如果不是首次，则在redis查找svrID和userID的对应关系，
选择上次为该user服务的entity。
    具体地，假设可用entity共有2个，分别为501，502。redis中维护一个availableEntities，存储可用的entity server ID，即availableEntities=map<uint32,bool>{501:true,502:true}, map value 为true 代表可以绑定新用户，false则代表禁止绑定新用户。另外redis中还维护了 和availableEntities中serverID对应的Map，用于记录userID和entityID绑定关系，bindMap = map<uint64,bool>。即 redis中 存在两个数据结构 ,availableEntities=map<uint32,bool> 和  binders= map<uint32, map<uint64,bool> >。availableEntities 的 keys 对应正在运行的所有entity [501，502] ，如果availableEntities[501]=false ,则代表负载均衡的时候禁止绑定新user，但不影响已经和501绑定的user，501可以正常为已绑定的旧user提供服务。如果availableEntities[501]=true,则代表负载均衡时可以绑定新user。

binders= map<uint32, map<uint64,bool> >。

binders的keys即availableEntities的keys 

binder_501:=binders[501]

binder_501[userID] , 如果存在为userID的key（无论value多少），则代表 userID 和 501绑定。

binder_501[userID] =false，代表对应的 user 没有在进行数据迁移，可以正常处理消息。

binder_501[userID] =true，代表对应的 user 正在进行数据迁移，暂时无法处理消息，SLB需要原地阻塞等待该user迁移结束，再发送消息。

len(binder_501) 即为 501上的负载人数（负载压力）。

当有user请求entityService时，遍历availableEntities的serverIDs，对于每个serverID，分三种情况处理：
1.对应的bindMap中存在为userID的key 且 bindMap[userID]=false,则直接将请求交给该serverID对应的entity
2.对应的bindMap中存在为userID的key 且 bindMap[userID]=true，则原地阻塞，等待通知，再发送请求。（ms级别的阻塞时长）
3.对应的bindMap中不存在为userID的key，说明user不和当前entity绑定，跳过（continue）
如果遍历结束后没有找到和user绑定的entity，则说明该user是首次负载均衡，选择availableEntities当前key对应的value==true 且 size最小 的map，设置bindMap[userID]=false,并将消息发给对应的entity。

热更新：
1.  运行中的旧entity为 entity501，entity502 , 新开entity503,entity504 。 503，504启动完成后将自己添加到 redis的availableEntities，代表可以对外服务，此时为availableEntities=map<int,bool>{501:true,502:true，503:true,504:true}。
2.  在admin web 后台页面下达热更新指令“entity_hotfix 501,502” 。adminsvr再分别发送消息给501，502，通知开始热更新。entity 会将自己在redis availableEntities中标记为false,代表进入热更新状态，不接受新用户绑定。此时availableEntities=map<int,bool>{501:false,502:false，503:true,504:true}.这里保证了新user将被导向503和504。
3.  假设501，502分别负载了1000个user，考虑将这总共2000个user迁移到新的503或504上。定义501上的1000个user依次为user1,user2,user3...user1000 ,
    502上的1000个user依次为user1001,user1002,user1003,...user2000. adminsvr 通知消息 smsg.Ad2EnNoticeHotfix 给 旧entity [501，502]。以501为例，依次迁移user1,user2,user3...user1000.
    轮到某个user迁移时，比如user1，先标记 map501[user1.userID]=true (map value:  true 代表正在进行数据迁移，禁止处理消息，false代表可以正常处理消息)（负载均衡时会根据此标记决定是否阻塞等待），然后将user1的缓存数据落地，执行user1的 Logout() ，让其在entity501上登出（不影响其他服务的user在线状态，比如此时user1在lobby上还是在线的，gate和客户端的socket连接也保持）。再从503，504中找个负载压力最小的，假设是503压力小，那么让user1在503上登录，再删除binde_501 中和user1对应的key，至此，user1不再与501绑定，而与503绑定。最后通过redis的发布/订阅机制，发布消息 ：user1已完成数据迁移，订阅方收到消息会结束阻塞。此时，对于user1来说，已经完成了entity热更新且整个过程客户端无感。
4.  当旧entity 完成了所有user的迁移时，可以关闭自己的进程。当所有旧entity进程都关闭后，即为整个系统的热更新完成。

关于热更新过程用户是否无感的分析：
    热更新的最小单位不是一整个entity，而是一个user。对于某个user来说，如果在热更之前没有绑定在旧的entity上，那么将会被直接绑定在新的entity上，由新entity处理其请求；如果在热更之前已经绑定在旧entity上，那么在轮到该user数据迁移之前的一段时间内，仍由旧entity处理其请求，在迁移进行中时，请求发送者会原地阻塞等待，直到收到迁移结束的通知消息，此后的消息都将由新entity处理。原地阻塞多久？如果太久，会导致用户有感。于是考虑阻塞时长：阻塞时长即单个user的迁移时长，主要耗时在旧entity缓存数据落地和新entity缓存加载，也就是 1次 mysql update 和 1次 mysql select 。阻塞时长和Mysql性能直接挂钩，以谷歌云 4c16G 的Mysql实例为例，使用sysbench 做压力测试，读写混合下的QPS为 7800 左右，即平均一次读写耗时 0.13ms，加上其他耗时，旧entity的Logout和新entity的Login等等，粗略估计是 ms级别。所以阻塞时长是 ms级别。
	综上所述，任意一个user，在整个热更过程中，其请求总会被及时处理，客户端无感（不会丢失，不会延迟太久）。



## 核心代码：

#### 	负载均衡相关：

```go
package appframe

import (
	"MX1/baselib/framework/netcluster"
	"MX1/baselib/sgslib/remotedic"
	"MX1/gameshared/redisclient/goredis"
	"errors"
	"fmt"
	"github.com/hashicorp/go-uuid"
	"github.com/sirupsen/logrus"
	"math"
	"math/rand"
	"sync/atomic"
	"time"
)

// LoadBalance 接口, 用于 Service 负载均衡实现.
type LoadBalance interface {
	Available() bool
	GetServerID(ext uint64) (uint32, bool)
	OnServerEvent(svrID uint32, event netcluster.SvrEvent)
}

// Application 和 GateApplication 都实现了这个接口.
type iGetAvailableServerIDs interface {
	GetAvailableServerIDs(typ ServerType) []uint32
}


// WithLoadBalanceRandom 随机选择服务节点负载均衡策略.
// 参数 app 可以是 *Application, 也可以是 *GateApplication 对象.
func WithLoadBalanceRandom(app iGetAvailableServerIDs, svrType ServerType) LoadBalance {
	return &random{app: app, typ: svrType}
}

// WithLoadBalanceSingleton 单节点服务负载均衡策略 (即无策略), 目的是统一抽象.
// 参数 app 可以是 *Application, 也可以是 *GateApplication 对象.
func WithLoadBalanceSingleton(app iGetAvailableServerIDs, svrType ServerType) LoadBalance {
	return &singleton{app: app, typ: svrType}
}

func WithLoadBalanceConsistentMapping(app iGetAvailableServerIDs, svrType ServerType, client *goredis.RedisClient) LoadBalance {
	return &consistentMapping{
		app:                  app,
		typ:                  svrType,
		ConsistentGlobalData: NewConsistentGlobalData(svrType, client),
	}
}


// 支持热更新的一致性负载均衡实现

type ConsistentGlobalData struct {
	slbRemoteBinders // 存储在redis的 map<uint32,map<uint64,bool> >Binders .  Binders[svrID][userID]=isMigrating
    AvailableServers remotedic.MapU32B // 存储在redis的 availableEntities : map<uint32,bool>
    
    RedisC           *goredis.RedisClient
	LockToken        atomic.Uint64
	SvrType          ServerType
}

type consistentMapping struct {
	*ConsistentGlobalData

	app iGetAvailableServerIDs
	typ ServerType
}


func (cm *consistentMapping) GetServerID(ext uint64) (uint32, bool) {
	return cm.getServerIDWithUserID(ext)
}

// GetServerIDWithUserID 根据userID获取服务节点ID （如果是第一次获取，则获取负载压力最小的服务节点，并记录映射关系。之后再获取直接返回映射关系记录的节点）
func (cm *consistentMapping) getServerIDWithUserID(userID uint64) (svrID uint32, ok bool) {
	// 读写redis数据时，使用分布式锁
    token := GenerateLockToken(cm.typ, userID) // 谁上的锁就由谁来解锁，身份凭证为token 。需要在分布式环境下唯一
	cm.LockMyself(token)
	defer cm.UnlockMyself(token)

	// 先尝试查找与userID绑定的svrID，同时统计各服务的负载压力

	var minLoadLevel int32 = math.MaxInt32
	var target uint32

	cm.RangeBinders(cm.typ, func(id uint32, binder *remotedic.MapU64BImp) bool {

		size := binder.Size() // 负载了多少user
		if canBind := cm.AvailableServers.Get(id); canBind && minLoadLevel > size {
			minLoadLevel = size
			target = id
		}

		if !binder.Exists(userID) {
			return true // 等价于 for 语句内的 continue
		}
		// 找到了绑定的svrID
		isMigrating := binder.Get(userID)
		if !isMigrating {
			// 目标服务可以正常处理该user的消息，直接返回
			svrID = id
			ok = true
			return false // 等价于 for 语句内的 break
		} else {
			// 正在热更新，数据迁移中
			// 暂时(ms级别)无法处理该user的消息，在这里阻塞等待，直到数据迁移结束
			channel := GenerateDataMigrateLockKey(cm.typ, userID)
			cm.RedisC.Subscribe(channel)
			_, err := cm.RedisC.ReceiveMessageTimeout(channel, time.Second*5) // 正常情况下，只会阻塞ms级别时间
			if err != nil {
				logrus.Error("consistentMapping ReceiveMessageTimeout err=", err)
				return false
			}
			svrID = id
			ok = true
			return false
		}
	})

	if ok {
		return
	}

	// 没有与userID绑定的svrID，新分配一个负载压力最小的服务 （上面已经统计过）

	if target == 0 {
		return 0, false
	}

	cm.GetBinderMapU64B(target, cm.typ).Set(userID, false) // 记录映射关系

	return target, true
}


```

### admin下达热更新指令相关：

![image-20240105164605759](img\image-20240105164605759.png)

点击"Entity热更新"后，会发送http请求到adminsvr,对应的handler如下

```go

// HotfixEntityServer entity热更新
func HotfixEntityServer(w http.ResponseWriter, r *http.Request) {
	// Parse query parameters
	nodes := r.URL.Query()["nodes[]"]
    
	response := map[string]interface{}{
		"status":  "success",
		"message": "Received nodes",
		"nodes":   nodes,
	}

	var ids = make([]uint32, 0, len(nodes))
	for _, server := range nodes {
		svrID, err := strconv.ParseUint(server, 10, 32)
		if err != nil {
			fmt.Fprint(w, "invalid server list")
			return
		}
		ids = append(ids, uint32(svrID))
	}

	for _, id := range ids {
		app.GetServer(id).SendMsg(&smsg.Ad2EnNoticeHotfix{MigrationPerSec: 100}, 0)
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

```

即指定501进行数据迁移，admin会发送smsg.Ad2EnNoticeHotfix给501。501收到消息后，开始做如下操作：

```go

func onAd2EnNoticeHotfix(sender appframe.Server, msg *smsg.Ad2EnNoticeHotfix) {

	if !isMigrating.CompareAndSwap(false, true) { // entity进程的整个生命周期只接受一次 热更新数据迁移
		return
	}

	svrID, svrType := AppInstance.ID(), appframe.ServerType(AppInstance.SlaveConfig().ServerType)
	cmGlobal := appframe.NewConsistentGlobalData(svrType, cmRedisC)
	cmGlobal.SetServerHotfix(svrID)

	// 开始数据迁移，在本服务上有缓存的都要迁移，其中分两种：
	// 1.在线玩家（一定有缓存）
	// 2.当前是离线状态，但最近有上线过，缓存还保留着
	util.SafeGo(func() {
		binder := cmGlobal.GetBinderMapU64B(svrID, svrType)
		d := time.Second / time.Duration(msg.MigrationPerSec)

		wg := sync.WaitGroup{}

		binder.Range(func(userID uint64, isMigrating bool) bool {
			cmGlobal.SetUserMigrating(userID, svrID)

			wg.Add(1)
			UserDBInstance.GetUser(userID, func(user *userdb.User, err error) {
				defer wg.Done()
				if err != nil {
					return
				}
				if onlineMgr.IsUserOnline(userID) { // 让在线玩家从当前entity下线 （仅从entity下线，不影响其他服务的user在线状态）
					doLogout(user)
				}
				user.Sync2DB() // 脏数据落地

				cmGlobal.UnbindUser2Svr(userID, svrID) // 删除绑定关系 ，当前user重新变为自由身，可以找新的entity绑定

				// entity -> lobby 当前entity通知lobby换个新的entity重新登录指定user
				AppInstance.GetService(MX1.SvrTypeLobby).SendMsg(&smsg.EsLsReLogin{Msg: user.LsEsReqLoginMsg}, userID)

				channel := appframe.GenerateDataMigrateLockKey(svrType, userID)
				cmGlobal.RedisC.Publish(channel, "data migrate finish") // 发布消息：当前user迁移结束
				logrus.WithField("userID", userID).Debug("data migrate finish")
			})

			time.Sleep(d) // 有Mysql写操作，慢慢执行任务，降低对数据库的压力
			return true
		})

		wg.Wait() // 等到所有user迁移结束，entity就可以关闭
		AppInstance.Exit()
	})

}
```

### 一些需要注意的实现细节：

缓存过期时，解除user和entity的绑定

entity启动时，将自己注册到availableEntities；关闭时，将自己从availableEntities中删除



## 热更新演练

windwos平台。

编译 all-in-one.exe 

编译 entitysvr_v_1.exe，版本1.0 的entity .

编译 entitysvr_v_2.exe，版本2.0 的entity. 

两个版本的entity代码的区别在于：

```go
//  entitysvr_v_1.exe

func (r Register) OnReqTestEntityHotfix(sender appframe.Session, req *cmsg.CReqTestEntityHotfix) {
	version := "1.0"
	sender.SendMsg(&cmsg.SRespTestEntityHotfix{EntityVersion: version})
	logrus.Info("OnReqTestEntityHotfix Entity version = ", version)
}

```

```go
//  entitysvr_v_2.exe

func (r Register) OnReqTestEntityHotfix(sender appframe.Session, req *cmsg.CReqTestEntityHotfix) {
	version := "2.0"
	sender.SendMsg(&cmsg.SRespTestEntityHotfix{EntityVersion: version})
	logrus.Info("OnReqTestEntityHotfix Entity version = ", version)
}

```

对于客户端的消息 CReqTestEntityHotfix ，返回一个 version。



1. 运行 all-in-one.exe -noEnity=true 。即开启除了entity以外的所有服务。

2. 运行 entity_v_1.exe -name=entity1 . 开启 entity1  ，svrID=501

3. 运行压测程序，模拟10个客户端，登录后，不停地向服务端发送CReqTestEntityHotfix消息，打印收到的回复SRespTestEntityHotfix，观察其中的version。

   ![image-20240105171231228](img\image-20240105171231228.png)

   ​	可以看到10个user都收到了 1.0的 version 回复

   ​	

   ![image-20240105171210885](img\image-20240105171210885.png)

   ​	entity 501 这边 ，也打印了发送给客户端的内容 

   

4. 开始热更新操作：运行 entity_v_2.exe -name=entity2 , 用版本2.0的entity 开启entity2，svrID=502.

5. admin 后台操作，选择svrID=501，点击 "Entity热更新"按钮。系统开始entity热更新

6. 持续观察程序打印的日志

   ![image-20240105171336987](img\image-20240105171336987.png)

​	可以看到，10个客户端都得到了 verison 2.0 ，已经热更新成功。期间客户端没有掉线，没有请求被丢失。

​	![image-20240105171359587](img\image-20240105171359587.png)

​	而entity 501已经完成10个玩家的数据迁移，自动关闭了。

​	![image-20240105171407744](img\image-20240105171407744.png)

​	entity 502 则在不断的处理10个客户端的消息，不停地在回复 version 2.0. 
